import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import silhouette_score, davies_bouldin_score
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Segmentaci√≥n de Pacientes - C√°ncer de Mama",
    page_icon="üè•",
    layout="wide"
)

# T√≠tulo principal
st.title("üè• Sistema de Clustering para Segmentaci√≥n de Pacientes")
st.markdown("### An√°lisis No Supervisado - C√°ncer de Mama (Caja Blanca)")
st.markdown("---")

# Funci√≥n para cargar datos
@st.cache_data
def load_data():
    """Carga el dataset de Breast Cancer desde sklearn"""
    from sklearn.datasets import load_breast_cancer
    
    data = load_breast_cancer()
    df = pd.DataFrame(data.data, columns=data.feature_names)
    df['target'] = data.target  # 0=malignant, 1=benign (solo para referencia)
    
    return df, data.feature_names

# Cargar datos
df, feature_names = load_data()

# Mostrar informaci√≥n del dataset
st.sidebar.header("‚öôÔ∏è Configuraci√≥n del Modelo")
st.sidebar.markdown("---")

# Mostrar dataset
with st.expander("üìä Ver Dataset Original", expanded=False):
    st.dataframe(df, use_container_width=True)
    st.info(f"**Dimensiones:** {df.shape[0]} pacientes √ó {df.shape[1]} caracter√≠sticas")

# Preparar datos para clustering (sin la columna target)
X = df.drop('target', axis=1)

# Normalizaci√≥n de datos
st.sidebar.subheader("üîß Preprocesamiento")
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
st.sidebar.success("‚úì Datos normalizados con StandardScaler")

# Selecci√≥n del algoritmo
st.sidebar.markdown("---")
st.sidebar.subheader("ü§ñ Algoritmo de Clustering")
algorithm = st.sidebar.selectbox(
    "Selecciona el algoritmo:",
    ["K-Means", "Clustering Jer√°rquico Aglomerativo"]
)

# Configuraci√≥n de hiperpar√°metros
st.sidebar.markdown("---")
st.sidebar.subheader("üìà Hiperpar√°metros")

k_range = range(2, 11)
selected_k = st.sidebar.slider(
    "N√∫mero de clusters (k):",
    min_value=2,
    max_value=10,
    value=3,
    step=1
)

# Bot√≥n para ejecutar an√°lisis
run_analysis = st.sidebar.button("üöÄ Ejecutar An√°lisis", type="primary", use_container_width=True)

if run_analysis:
    # Secci√≥n 1: Grid Search para encontrar k √≥ptimo
    st.header("üìä 1. Optimizaci√≥n de Hiperpar√°metros (Grid Search)")
    
    with st.spinner("Calculando m√©tricas para diferentes valores de k..."):
        silhouette_scores = []
        davies_bouldin_scores = []
        
        for k in k_range:
            if algorithm == "K-Means":
                model = KMeans(n_clusters=k, random_state=42, n_init=10)
            else:
                model = AgglomerativeClustering(n_clusters=k)
            
            labels = model.fit_predict(X_scaled)
            
            # Calcular m√©tricas
            sil_score = silhouette_score(X_scaled, labels)
            db_score = davies_bouldin_score(X_scaled, labels)
            
            silhouette_scores.append(sil_score)
            davies_bouldin_scores.append(db_score)
    
    # Crear gr√°ficos de m√©tricas
    col1, col2 = st.columns(2)
    
    with col1:
        fig_sil = px.line(
            x=list(k_range),
            y=silhouette_scores,
            markers=True,
            title="Silhouette Score vs N√∫mero de Clusters",
            labels={'x': 'N√∫mero de Clusters (k)', 'y': 'Silhouette Score'}
        )
        fig_sil.update_traces(line_color='#1f77b4', marker=dict(size=10))
        fig_sil.update_layout(height=400)
        st.plotly_chart(fig_sil, use_container_width=True)
        st.info("üìà **Mayor Silhouette Score = Mejor** (rango: -1 a 1)")
    
    with col2:
        fig_db = px.line(
            x=list(k_range),
            y=davies_bouldin_scores,
            markers=True,
            title="Davies-Bouldin Index vs N√∫mero de Clusters",
            labels={'x': 'N√∫mero de Clusters (k)', 'y': 'Davies-Bouldin Index'}
        )
        fig_db.update_traces(line_color='#ff7f0e', marker=dict(size=10))
        fig_db.update_layout(height=400)
        st.plotly_chart(fig_db, use_container_width=True)
        st.info("üìâ **Menor Davies-Bouldin = Mejor** (‚â• 0)")
    
    # Recomendaci√≥n de k √≥ptimo
    optimal_k_sil = list(k_range)[np.argmax(silhouette_scores)]
    optimal_k_db = list(k_range)[np.argmin(davies_bouldin_scores)]
    
    st.success(f"üí° **K √≥ptimo seg√∫n Silhouette:** {optimal_k_sil} | **K √≥ptimo seg√∫n Davies-Bouldin:** {optimal_k_db}")
    
    st.markdown("---")
    
    # Secci√≥n 2: Clustering con k seleccionado
    st.header(f"üéØ 2. Resultados del Clustering (k={selected_k})")
    
    # Entrenar modelo con k seleccionado
    if algorithm == "K-Means":
        final_model = KMeans(n_clusters=selected_k, random_state=42, n_init=10)
    else:
        final_model = AgglomerativeClustering(n_clusters=selected_k)
    
    clusters = final_model.fit_predict(X_scaled)
    
    # Calcular m√©tricas finales
    final_silhouette = silhouette_score(X_scaled, clusters)
    final_db = davies_bouldin_score(X_scaled, clusters)
    
    # Mostrar m√©tricas
    col1, col2, col3 = st.columns(3)
    col1.metric("üîµ Algoritmo", algorithm)
    col2.metric("üìä Silhouette Score", f"{final_silhouette:.4f}")
    col3.metric("üìâ Davies-Bouldin Index", f"{final_db:.4f}")
    
    st.markdown("---")
    
    # Secci√≥n 3: Visualizaci√≥n con PCA
    st.header("üî¨ 3. Visualizaci√≥n con PCA (2 Componentes)")
    
    with st.spinner("Aplicando PCA y generando visualizaci√≥n..."):
        # Aplicar PCA para reducci√≥n a 2D
        pca = PCA(n_components=2, random_state=42)
        X_pca = pca.fit_transform(X_scaled)
        
        # Crear DataFrame para visualizaci√≥n
        df_pca = pd.DataFrame({
            'PC1': X_pca[:, 0],
            'PC2': X_pca[:, 1],
            'Cluster': clusters.astype(str),
            'Target_Real': df['target'].map({0: 'Maligno', 1: 'Benigno'})
        })
        
        # Varianza explicada
        var_explained = pca.explained_variance_ratio_
        st.info(f"üìä **Varianza explicada:** PC1 = {var_explained[0]:.2%} | PC2 = {var_explained[1]:.2%} | Total = {var_explained.sum():.2%}")
        
        # Gr√°fico de dispersi√≥n interactivo
        fig_pca = px.scatter(
            df_pca,
            x='PC1',
            y='PC2',
            color='Cluster',
            title=f'Visualizaci√≥n de Clusters en Espacio PCA ({algorithm})',
            labels={'PC1': f'PC1 ({var_explained[0]:.1%})', 'PC2': f'PC2 ({var_explained[1]:.1%})'},
            hover_data=['Target_Real'],
            color_discrete_sequence=px.colors.qualitative.Set2
        )
        fig_pca.update_traces(marker=dict(size=8, line=dict(width=0.5, color='white')))
        fig_pca.update_layout(height=600)
        st.plotly_chart(fig_pca, use_container_width=True)
    
    st.markdown("---")
    
    # Secci√≥n 4: Distribuci√≥n de Clusters
    st.header("üì¶ 4. Distribuci√≥n de Pacientes por Cluster")
    
    cluster_counts = pd.Series(clusters).value_counts().sort_index()
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.dataframe(
            pd.DataFrame({
                'Cluster': cluster_counts.index,
                'Pacientes': cluster_counts.values,
                'Porcentaje': (cluster_counts.values / len(clusters) * 100).round(2)
            }),
            use_container_width=True
        )
    
    with col2:
        fig_dist = px.bar(
            x=cluster_counts.index,
            y=cluster_counts.values,
            title="N√∫mero de Pacientes por Cluster",
            labels={'x': 'Cluster', 'y': 'N√∫mero de Pacientes'},
            color=cluster_counts.index.astype(str),
            color_discrete_sequence=px.colors.qualitative.Set2
        )
        fig_dist.update_layout(showlegend=False, height=400)
        st.plotly_chart(fig_dist, use_container_width=True)
    
    st.markdown("---")
    
    # Secci√≥n 5: An√°lisis de Caracter√≠sticas por Cluster
    st.header("üîç 5. Caracter√≠sticas Promedio por Cluster")
    
    df_analysis = df.copy()
    df_analysis['Cluster'] = clusters
    
    # Top 10 caracter√≠sticas m√°s importantes
    top_features = list(feature_names[:10])
    cluster_profiles = df_analysis.groupby('Cluster')[top_features].mean()
    
    st.dataframe(cluster_profiles.style.background_gradient(cmap='RdYlGn', axis=1), use_container_width=True)
    
    st.success("‚úÖ An√°lisis completado exitosamente!")

else:
    st.info("üëà Configura los par√°metros en el panel lateral y presiona **'Ejecutar An√°lisis'** para comenzar.")
    
    # Mostrar informaci√≥n sobre el dataset
    st.header("‚ÑπÔ∏è Informaci√≥n del Dataset")
    st.markdown("""
    Este sistema analiza el **Wisconsin Diagnostic Breast Cancer Dataset** que contiene:
    
    - **569 pacientes** con diagn√≥stico de c√°ncer de mama
    - **30 caracter√≠sticas** extra√≠das de im√°genes digitalizadas de aspiraci√≥n con aguja fina (FNA)
    - Las caracter√≠sticas incluyen: radio, textura, per√≠metro, √°rea, suavidad, compacidad, concavidad, puntos c√≥ncavos, simetr√≠a y dimensi√≥n fractal
    
    **Objetivo:** Segmentar pacientes en grupos homog√©neos usando t√©cnicas de clustering no supervisado.
    """)
    
    st.markdown("---")
    st.markdown("**Desarrollado por:** Data Science Team | **Dataset:** UCI Machine Learning Repository")